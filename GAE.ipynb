{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJdivsyNNkzR",
        "outputId": "36b7fb95-c270-4544-cd3b-cd8b5975590e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.11 in /usr/local/lib/python3.10/dist-packages (2.11.0)\n",
            "Requirement already satisfied: tensorflow_gnn in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (1.68.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (3.12.1)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (2.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (1.24.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (24.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (1.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11) (0.37.1)\n",
            "Requirement already satisfied: apache-beam<2.47.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_gnn) (2.46.0)\n",
            "Requirement already satisfied: google-vizier>=0.0.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow_gnn) (0.1.20)\n",
            "Requirement already satisfied: ml-collections in /usr/local/lib/python3.10/dist-packages (from tensorflow_gnn) (1.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from tensorflow_gnn) (3.4.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow_gnn) (9.0.0)\n",
            "Requirement already satisfied: tensorflow>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_gnn) (2.11.1)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.7)\n",
            "Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (3.10.12)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.3.1.1)\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.10.0)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.19)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.7.3)\n",
            "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.21.0)\n",
            "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.6.1)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (3.13.0)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.25.0)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (2024.2)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (2024.11.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.32.3)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.23.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow-gpu==2.11) (0.45.1)\n",
            "Requirement already satisfied: attrs==23.1.0 in /usr/local/lib/python3.10/dist-packages (from google-vizier>=0.0.13->tensorflow_gnn) (23.1.0)\n",
            "Requirement already satisfied: portpicker>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.5.2)\n",
            "Requirement already satisfied: grpcio-tools>=1.35.0 in /usr/local/lib/python3.10/dist-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.48.2)\n",
            "Requirement already satisfied: googleapis-common-protos>=1.56.4 in /usr/local/lib/python3.10/dist-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.63.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.4 in /usr/local/lib/python3.10/dist-packages (from google-vizier>=0.0.13->tensorflow_gnn) (2.0.36)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu==2.11) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu==2.11) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu==2.11) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu==2.11) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu==2.11) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu==2.11) (3.1.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from ml-collections->tensorflow_gnn) (6.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11) (1.3.1)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam<2.47.0->tensorflow_gnn) (0.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.22.0,>=0.8->apache-beam<2.47.0->tensorflow_gnn) (3.2.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker>=1.3.1->google-vizier>=0.0.13->tensorflow_gnn) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4->google-vizier>=0.0.13->tensorflow_gnn) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11) (3.2.2)\n",
            "Requirement already satisfied: spektral in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from spektral) (1.4.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from spektral) (5.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from spektral) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spektral) (1.24.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from spektral) (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from spektral) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from spektral) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from spektral) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from spektral) (4.67.1)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from spektral) (2.11.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.68.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (3.12.1)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (24.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (0.37.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->spektral) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->spektral) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->spektral) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (2024.12.14)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->spektral) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2.0->spektral) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->spektral) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->spektral) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->spektral) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->spektral) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->spektral) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->spektral) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->spektral) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->spektral) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->spektral) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->spektral) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->spektral) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->spektral) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->spektral) (3.2.2)\n",
            "Requirement already satisfied: kneed in /usr/local/lib/python3.10/dist-packages (0.8.5)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from kneed) (1.24.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from kneed) (1.13.1)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
        "\n",
        "!pip install tensorflow-gpu==2.11 tensorflow_gnn\n",
        "!pip install spektral\n",
        "!pip install kneed\n",
        "\n",
        "from google.colab import drive\n",
        "from astropy.io import fits\n",
        "from astropy.table import Table\n",
        "from astropy.table import Column\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "import tensorflow as tf\n",
        "import tensorflow_gnn as tfgnn\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from spektral.layers import GCNConv\n",
        "from spektral.utils import normalized_adjacency, add_self_loops\n",
        "from kneed import KneeLocator\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics import calinski_harabasz_score\n",
        "from astropy.cosmology import Planck18 as cosmo\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/My Drive/FS2_Marguerite_positive_new.fits'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WN0fIuKOZwM",
        "outputId": "fc34e029-5145-4f64-e030-e4b192a5c479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Open selected data\n",
        "with fits.open(file_path, memmap=True) as hdul:\n",
        "    table = Table(hdul[1].data)\n",
        "\n",
        "    #Chose only some columns from the table\n",
        "    selected_table = table[['OBJECT_ID', 'RIGHT_ASCENSION', 'DECLINATION',\n",
        "                            'PHZ_MEDIAN', 'Z_SPE','FLUX_VIS_APER',\n",
        "                            'FLUXERR_VIS_APER', 'FLUX_Y_TOTAL_UNIF',\n",
        "                            'FLUXERR_Y_TOTAL_UNIF','FLUX_J_TOTAL_UNIF',\n",
        "                            'FLUXERR_J_TOTAL_UNIF','FLUX_H_TOTAL_UNIF',\n",
        "                            'FLUXERR_H_TOTAL_UNIF',]]\n",
        "\n",
        "\n",
        "#Select data inside a square (0.8ra x 0.8dec)\n",
        "rad_min, rad_max = 148.0, 148.8\n",
        "dec_min, dec_max = 1.5,2.3\n",
        "\n",
        "\n",
        "filtered_data = table[(table['RIGHT_ASCENSION'] >= rad_min) &\n",
        "                     (table['RIGHT_ASCENSION'] <= rad_max) &\n",
        "                     (table['DECLINATION'] >= dec_min) &\n",
        "                     (table['DECLINATION'] <= dec_max)&\n",
        "                     (table['Z_SPE'] >= 0.0029)]\n",
        "\n",
        "print(f\"Filtered data: {len(filtered_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb8Oj-KwO0si",
        "outputId": "917d7efe-6e5e-4983-c16a-85159386ac64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dati filtrati: 160490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute colors YJ, JH and magnitudes H,Y,J\n",
        "\n",
        "flux_table = filtered_data[['OBJECT_ID','RIGHT_ASCENSION', 'DECLINATION',\n",
        "                            'PHZ_MEDIAN','Z_SPE', 'FLUX_VIS_APER',\n",
        "                            'FLUX_Y_TOTAL_UNIF','FLUX_J_TOTAL_UNIF',\n",
        "                            'FLUX_H_TOTAL_UNIF']]\n",
        "\n",
        "colorYJ = []\n",
        "colorJH = []\n",
        "magnitudeH = []\n",
        "magnitudeY  = []\n",
        "magnitudeJ  = []\n",
        "number = 0\n",
        "\n",
        "for i in range(len(flux_table)):\n",
        "    fluxY = flux_table['FLUX_Y_TOTAL_UNIF'][i]\n",
        "    fluxJ = flux_table['FLUX_J_TOTAL_UNIF'][i]\n",
        "    fluxH = flux_table['FLUX_H_TOTAL_UNIF'][i]\n",
        "\n",
        "    if fluxY > 0 and fluxJ > 0 and fluxH > 0:\n",
        "        x = -2.5 * np.log10(fluxY / fluxJ)\n",
        "        y = -2.5 * np.log10(fluxJ / fluxH)\n",
        "        mH = -2.5 * np.log10(fluxH) + 23.9\n",
        "        mY = -2.5 * np.log10(fluxY) + 23.9\n",
        "        mJ = -2.5 * np.log10(fluxJ) + 23.9\n",
        "    else:\n",
        "        x = 0\n",
        "        y = 0\n",
        "        mH = 0\n",
        "        mY = 0\n",
        "        mJ = 0\n",
        "        number = number+1\n",
        "\n",
        "    colorYJ.append(x)\n",
        "    colorJH.append(y)\n",
        "    magnitudeH.append(mH)\n",
        "    magnitudeY.append(mY)\n",
        "    magnitudeJ.append(mJ)\n",
        "\n",
        "new_column = Column(colorYJ, name='COLOR Y-J')\n",
        "new_column1 = Column(colorJH, name='COLOR J-H')\n",
        "new_column2 = Column(magnitudeH, name='MAGNITUDE H')\n",
        "new_column3 = Column(magnitudeY, name='MAGNITUDE Y')\n",
        "new_column4 = Column(magnitudeJ, name='MAGNITUDE J')\n",
        "\n",
        "#Append new columns for colors and magnitudes to the existing table\n",
        "flux_table.add_column(new_column)\n",
        "flux_table.add_column(new_column1)\n",
        "flux_table.add_column(new_column2)\n",
        "flux_table.add_column(new_column3)\n",
        "flux_table.add_column(new_column4)\n",
        "\n",
        "print(f'Number of data with flux minor or equal to zero: {number}')\n",
        "print(len(flux_table))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hLekyE7PELM",
        "outputId": "64631674-fc3f-4663-fa92-f33ee5b9f84e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero dati con flusso minore o uguale a zero: 685\n",
            "160490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete data with negative fluxes\n",
        "\n",
        "filtered_table = flux_table[(flux_table['COLOR Y-J'] != 0) &\n",
        "                            (flux_table['COLOR J-H'] != 0)]\n",
        "print(len(filtered_table))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFBjmi7CPJxF",
        "outputId": "110a3cd3-c674-43cf-9aa9-bb900ddce282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "159805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use K nearest neighbors to create the adjacency matrix\n",
        "\n",
        "galaxies = np.stack([\n",
        "    filtered_table['RIGHT_ASCENSION'],\n",
        "    filtered_table['DECLINATION'],\n",
        "    filtered_table['COLOR Y-J'],\n",
        "    filtered_table['COLOR J-H'],\n",
        "    filtered_table['MAGNITUDE H']\n",
        "], axis=1).astype(float)\n",
        "\n",
        "#Scale data\n",
        "scaler = StandardScaler()\n",
        "galaxies_scaled = scaler.fit_transform(galaxies)\n",
        "\n",
        "k = 40\n",
        "\n",
        "features = tf.constant(galaxies_scaled, dtype=tf.float32)\n",
        "adjacency_matrix = kneighbors_graph(galaxies_scaled, n_neighbors=k,\n",
        "                                    mode='distance',\n",
        "                                    include_self=False)\n",
        "\n",
        "#Normalize adjacency matrix between 0 and 1\n",
        "min_val = adjacency_matrix.data.min()\n",
        "max_val = adjacency_matrix.data.max()\n",
        "adjacency_matrix.data = (adjacency_matrix.data - min_val) / (max_val - min_val)\n",
        "\n",
        "#Set closest points closer to 1\n",
        "adjacency_matrix.data = 1 - adjacency_matrix.data\n",
        "\n",
        "#Convert into appriopriate format\n",
        "adjacency_matrix_coo = adjacency_matrix.tocoo()\n",
        "\n",
        "#Create the graph with edges and weights\n",
        "edges = tf.constant(adjacency_matrix_coo.nonzero(), dtype=tf.int64)\n",
        "weights = tf.constant(adjacency_matrix_coo.data, dtype=tf.float32)\n",
        "\n",
        "graph = tfgnn.GraphTensor.from_pieces(\n",
        "    node_sets = {\n",
        "        \"nodes\": tfgnn.NodeSet.from_fields(\n",
        "            features={\"features\": features},\n",
        "            sizes=[len(features)]\n",
        "        )\n",
        "    },\n",
        "    edge_sets={\n",
        "        \"edges\": tfgnn.EdgeSet.from_fields(\n",
        "            features={\"weights\": weights},\n",
        "            sizes=[edges.shape[1]],\n",
        "            adjacency=tfgnn.Adjacency.from_indices(\n",
        "                source=(\"nodes\", edges[:, 0]),\n",
        "                target=(\"nodes\", edges[:, 1])\n",
        "            )\n",
        "        )\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "id": "q4TXWqyQPSSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#K-means clustering classification with scaled data\n",
        "RA = galaxies_scaled[:,0]\n",
        "DEC = galaxies_scaled[:,1]\n",
        "ColorY_J = galaxies_scaled[:,2]\n",
        "ColorJ_H = galaxies_scaled[:,3]\n",
        "MagnitudeH = galaxies_scaled[:,4]\n",
        "\n",
        "\n",
        "coordinates = np.column_stack((ColorY_J, ColorJ_H, MagnitudeH, RA, DEC))\n",
        "\n",
        "\n",
        "#Try with different values of k (number of clusters)\n",
        "clusterNum = range(5, 30)\n",
        "distance = []\n",
        "\n",
        "for i in clusterNum:\n",
        "    k_means = KMeans(init = \"k-means++\", n_clusters = i, n_init = 12)\n",
        "    k_means.fit(coordinates)\n",
        "    #Save inertia (sum quadratic distances intra-cluster)\n",
        "    distance.append(k_means.inertia_)\n"
      ],
      "metadata": {
        "id": "_yrYPsrBm3MI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find elbow point (best number of k)\n",
        "knee_locator = KneeLocator(clusterNum, distance, curve=\"convex\", direction=\"decreasing\")\n",
        "\n",
        "elbow_point = knee_locator.knee\n",
        "print(f\"Elbow point: {elbow_point}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Byjc69jkn6K7",
        "outputId": "ccdbd3a6-aa78-478b-9b3e-a633752bc5ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elbow point: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Faccio K-Means con l'elbow point, nota che non vogliamo che le distanze tra i punti di un cluster siano troppo alte, ma non devono neanche\n",
        "#essere troppo basse\n",
        "#K-means using elbow point\n",
        "\n",
        "clusterNum = elbow_point\n",
        "\n",
        "k_means = KMeans(init = \"k-means++\", n_clusters = clusterNum, n_init = 12)\n",
        "k_means.fit(coordinates)\n",
        "labels = k_means.labels_ #dice ogni elemento del dataset a quale cluster è stato assegnato\n",
        "cluster_centers = k_means.cluster_centers_\n",
        "\n",
        "#Count number of elements in each cluster\n",
        "unique, counts = np.unique(labels, return_counts=True)\n",
        "\n",
        "for cluster, count in zip(unique, counts):\n",
        "    print(f\"Cluster {cluster}: {count} elements\")\n",
        "\n",
        "print(cluster_centers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OXXJB_cn_uQ",
        "outputId": "8b9874cd-e764-4175-e0cc-c26b5e0a7592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 0: 5963 elementi\n",
            "Cluster 1: 21563 elementi\n",
            "Cluster 2: 9807 elementi\n",
            "Cluster 3: 20807 elementi\n",
            "Cluster 4: 9195 elementi\n",
            "Cluster 5: 11842 elementi\n",
            "Cluster 6: 24416 elementi\n",
            "Cluster 7: 2910 elementi\n",
            "Cluster 8: 20011 elementi\n",
            "Cluster 9: 10920 elementi\n",
            "Cluster 10: 9358 elementi\n",
            "Cluster 11: 13013 elementi\n",
            "[[-1.32866029e+00  2.48824076e+00  7.50171515e-01 -8.60308728e-03\n",
            "  -2.33107581e-02]\n",
            " [-4.39579391e-01 -3.25582734e-01  2.84239193e-01 -9.24927719e-01\n",
            "   9.12652112e-01]\n",
            " [ 3.85042851e-02  1.54083188e-01 -2.02605634e+00 -9.31285529e-01\n",
            "   1.70313154e-01]\n",
            " [-4.68523869e-01 -3.31036862e-01  3.61272421e-01  9.42553524e-01\n",
            "  -8.38758114e-01]\n",
            " [-1.45200770e-02 -1.65483141e+00  9.67795130e-01 -2.17656502e-01\n",
            "  -2.01240695e-01]\n",
            " [ 9.87985640e-01  7.47687297e-01  2.72667298e-01 -6.27665392e-01\n",
            "   7.02206840e-01]\n",
            " [-1.69169563e-01 -7.02996195e-02  1.76746617e-01 -9.28506521e-01\n",
            "  -9.17144849e-01]\n",
            " [ 3.90874580e+00  6.40750685e-01  6.93483413e-01 -2.10169710e-02\n",
            "  -1.08092815e-01]\n",
            " [-2.62226446e-01 -2.61139055e-01  4.51956505e-01  9.13656243e-01\n",
            "   9.83885296e-01]\n",
            " [ 1.61537151e-03  6.67450950e-02 -1.20394433e+00  7.19698801e-01\n",
            "   9.47817122e-01]\n",
            " [-2.24318973e-02  5.21939717e-02 -1.70738009e+00  7.36033364e-01\n",
            "  -8.77058016e-01]\n",
            " [ 1.02999749e+00  5.99537253e-01  2.60189010e-01  6.65081582e-01\n",
            "  -7.20317304e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Silhouette Score\n",
        "silhouette_avg = silhouette_score(coordinates, labels)\n",
        "\n",
        "print(f\"Mean Silhouette Score: {silhouette_avg}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQtKQYXNout_",
        "outputId": "48432ba7-f5e9-4d1a-d48b-0f2def98056e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score medio: 0.1774513872135572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calinski-Harabasz Score\n",
        "ch_score = calinski_harabasz_score(coordinates, labels)\n",
        "print(f\"Calinski-Harabasz Score: {ch_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoVd5iHYtKNq",
        "outputId": "54774154-78f9-4b21-e95c-7119cebb575f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calinski-Harabasz Score: 22741.616057555573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check that values of adjacency matrix are normalized between 0 and 1\n",
        "\n",
        "values = adjacency_matrix.data\n",
        "\n",
        "#Find values out of range\n",
        "out_of_range_values = values[(values < 0) | (values > 1)]\n",
        "\n",
        "if len(out_of_range_values) > 0:\n",
        "    print(\"Values out of the interval [0, 1]:\", out_of_range_values)\n",
        "    print(\"Number of values out of the interval:\", len(out_of_range_values))\n",
        "else:\n",
        "    print(\"All values are in interval [0, 1].\")\n",
        "\n",
        "print(adjacency_matrix_coo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKrJq_RXvxdB",
        "outputId": "6bb4de09-37b6-403c-bb0c-b5c5a2ea3b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tutti i valori sono nell'intervallo [0, 1].\n",
            "  (0, 2)\t0.9965175987893231\n",
            "  (0, 59670)\t0.9844804691995199\n",
            "  (0, 117451)\t0.9840879396177237\n",
            "  (0, 114683)\t0.9813127114219512\n",
            "  (0, 117408)\t0.9805308197404992\n",
            "  (0, 58223)\t0.9793239231022838\n",
            "  (0, 6786)\t0.977265406022681\n",
            "  (0, 59003)\t0.9764323105538446\n",
            "  (0, 5729)\t0.9763910906430702\n",
            "  (0, 116434)\t0.9757159237304871\n",
            "  (0, 4184)\t0.9756090670653011\n",
            "  (0, 10658)\t0.9753682151572521\n",
            "  (0, 58057)\t0.9742078859057891\n",
            "  (0, 61224)\t0.973963377915438\n",
            "  (0, 59626)\t0.9736632628403089\n",
            "  (0, 3372)\t0.973445836169668\n",
            "  (0, 120904)\t0.9729861597698789\n",
            "  (0, 57315)\t0.9724657589263558\n",
            "  (0, 273)\t0.9717129393168255\n",
            "  (0, 63964)\t0.9715974634592234\n",
            "  (0, 95)\t0.9713230250969518\n",
            "  (0, 5123)\t0.9709516987190536\n",
            "  (0, 2452)\t0.970935024481945\n",
            "  (0, 3865)\t0.9705558493091656\n",
            "  (0, 58048)\t0.9700831913896439\n",
            "  :\t:\n",
            "  (159804, 136693)\t0.9768944378596249\n",
            "  (159804, 89181)\t0.976802913459789\n",
            "  (159804, 134775)\t0.9762653495918274\n",
            "  (159804, 44517)\t0.9761158897619673\n",
            "  (159804, 56617)\t0.9756787401221041\n",
            "  (159804, 91270)\t0.9756002348217208\n",
            "  (159804, 147425)\t0.9750128985172848\n",
            "  (159804, 34296)\t0.9749079594798848\n",
            "  (159804, 159798)\t0.9747868541039202\n",
            "  (159804, 42519)\t0.9743981766575233\n",
            "  (159804, 149936)\t0.9742614216172675\n",
            "  (159804, 78708)\t0.9739430637579443\n",
            "  (159804, 103202)\t0.9734227485711046\n",
            "  (159804, 82569)\t0.9732216032578042\n",
            "  (159804, 36021)\t0.9731723765404159\n",
            "  (159804, 114113)\t0.9731285442802352\n",
            "  (159804, 41228)\t0.9729868317623858\n",
            "  (159804, 105490)\t0.9726424736258091\n",
            "  (159804, 98385)\t0.97259018904685\n",
            "  (159804, 96902)\t0.9724126464764238\n",
            "  (159804, 109928)\t0.9722039510776086\n",
            "  (159804, 83622)\t0.9718290436152235\n",
            "  (159804, 82537)\t0.9714363802194922\n",
            "  (159804, 134808)\t0.9714069390628642\n",
            "  (159804, 41226)\t0.971406826176241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape after scaling:\", galaxies_scaled.shape)\n",
        "print(\"Mean of every column (after scaling):\", galaxies_scaled.mean(axis=0))\n",
        "print(\"Standard deviation of every column:\", galaxies_scaled.std(axis=0))\n",
        "print(\"Adjacency matrix shape:\", adjacency_matrix_coo.shape)\n",
        "print(\"Adjacency matrix type:\", adjacency_matrix_coo.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeDMCRaO-oKT",
        "outputId": "11b7fa64-7f6d-4b94-9508-a52532cfa52f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma dopo lo scaling: (159805, 5)\n",
            "Media di ogni colonna (dopo lo scaling): [-2.23092059e-14  2.58501577e-16 -8.89660292e-16 -3.38278123e-16\n",
            "  4.62869940e-11]\n",
            "Deviazione standard di ogni colonna: [1. 1. 1. 1. 1.]\n",
            "Forma della matrice di adiacenza: (159805, 159805)\n",
            "Tipo matrice di Adiacenza: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check some features of the graph\n",
        "\n",
        "num_nodes = graph.node_sets[\"nodes\"].sizes[0]\n",
        "num_edges = graph.edge_sets[\"edges\"].sizes[0]\n",
        "print(f\"Number of nodes: {num_nodes}\")\n",
        "print(f\"Number of edges: {num_edges}\")\n",
        "\n",
        "num_nodes = tf.cast(num_nodes, tf.int64)\n",
        "num_edges = tf.cast(num_edges, tf.int64)\n",
        "\n",
        "max_edges = num_nodes * (num_nodes - 1) // 2\n",
        "density = num_edges / max_edges\n",
        "print(f\"Graph density: {density}\")\n",
        "print(f\"Maximum number of edges: {max_edges}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H2w-RMvFD4B",
        "outputId": "2fd89f2c-98a1-421f-d3b9-4a80f9fb4244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero di nodi: 159805\n",
            "Numero di archi: 6392199\n",
            "Densità del grafo: 0.0005006131729164917\n",
            "Numero massimo di connessioni: 12768739110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create sparse matrix with tf.sparse from Tensorflow\n",
        "\n",
        "n_nodes = galaxies_scaled.shape[0]\n",
        "n_features = galaxies_scaled.shape[1]\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Note: adjacency_matrix_coo was already a sparse matrix, but creating it using\n",
        "tf.sparse makes it readable for future operations using Tensorflow.\n",
        "\"\"\"\n",
        "\n",
        "adj = tf.sparse.SparseTensor(\n",
        "    indices=np.vstack((adjacency_matrix_coo.row, adjacency_matrix_coo.col)).T,\n",
        "    values=adjacency_matrix_coo.data,\n",
        "    dense_shape=adjacency_matrix_coo.shape\n",
        "\n",
        ")\n",
        "\n",
        "#Add self loops to the adjacency matrix\n",
        "self_loops = tf.sparse.SparseTensor(\n",
        "    indices=[[i, i] for i in range(adj.shape[0])],\n",
        "    values=tf.ones(adj.shape[0], dtype=adj.dtype),\n",
        "    dense_shape=adj.shape\n",
        ")\n",
        "\n",
        "\n",
        "adj_with_self_loops = tf.sparse.add(adj, self_loops)\n",
        "\n",
        "\n",
        "features = tf.convert_to_tensor(galaxies_scaled, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "ch8dD6LdXB6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S3rmA2Eel-j",
        "outputId": "ad503fca-c640-4bcb-c533-2b8f0fb05ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1.1664892  -1.5366001  -0.84484017 -0.9340779  -3.151268  ]\n",
            " [ 1.1775665  -1.5447432  -0.7698594  -0.87228596 -2.2857234 ]\n",
            " [ 1.2028859  -1.524551   -0.80394244 -0.8879684  -3.0880866 ]\n",
            " ...\n",
            " [ 1.565006    1.2685736  -0.46795356  1.7995236   0.9867769 ]\n",
            " [ 1.511466    1.3483487   0.8669721   1.99705     0.79046714]\n",
            " [ 1.3352852   1.7367977  -0.963896    1.4116533   0.27871838]], shape=(159805, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(adj_with_self_loops)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot2iYAgQgAd-",
        "outputId": "16cfc623-5de1-4b59-f271-66821eda9d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparseTensor(indices=tf.Tensor(\n",
            "[[     0      0]\n",
            " [     0      2]\n",
            " [     0  59670]\n",
            " ...\n",
            " [159804 134808]\n",
            " [159804  41226]\n",
            " [159804 159804]], shape=(6552005, 2), dtype=int64), values=tf.Tensor([1.         0.9965176  0.98448047 ... 0.97140694 0.97140683 1.        ], shape=(6552005,), dtype=float64), dense_shape=tf.Tensor([159805 159805], shape=(2,), dtype=int64))\n",
            "tf.Tensor(0.0, shape=(), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the GAE model\n",
        "\n",
        "class GraphAutoencoder(Model):\n",
        "    def __init__(self, hidden_dim, latent_dim):\n",
        "        super(GraphAutoencoder, self).__init__()\n",
        "        self.gcn1 = GCNConv(hidden_dim, activation=\"relu\")\n",
        "        self.gcn2 = GCNConv(hidden_dim // 2, activation=\"relu\")\n",
        "        self.gcn3 = GCNConv(latent_dim, activation=None)\n",
        "\n",
        "    def encoder(self, x, adj):\n",
        "        #Apply GCN layers to obtain embeddings\n",
        "        z = self.gcn1([x, adj])\n",
        "        z = self.gcn2([z, adj])\n",
        "        z = self.gcn3([z, adj])\n",
        "        #Normalize features vector to mean = 0 and dev_std = 1\n",
        "        z = tf.nn.l2_normalize(z, axis=1)\n",
        "        return z\n",
        "\n",
        "    def decoder(self, z, adj_indices):\n",
        "        \"\"\"\n",
        "        Reconstruct the adjacency matrix with inner product.\n",
        "        Calculates the inner product only for the specified indices\n",
        "        (sparse matrix), the highest the inner product the most similar\n",
        "        are two vectors (elements of z).\n",
        "        \"\"\"\n",
        "        reconstructed_values = tf.reduce_sum(\n",
        "            tf.gather(z, adj_indices[:, 0]) * tf.gather(z, adj_indices[:, 1]),\n",
        "            axis=1)\n",
        "\n",
        "        #Normalize between 0 and 1, as for the initial adjacency matrix\n",
        "        min_val = tf.reduce_min(reconstructed_values)\n",
        "        max_val = tf.reduce_max(reconstructed_values)\n",
        "        reconstructed_values = (reconstructed_values - min_val) / (max_val - min_val)\n",
        "\n",
        "        #Create a SparseTensor for reconstructed matrix with tf.sparse\n",
        "        reconstructed_adj = tf.sparse.SparseTensor(\n",
        "            indices=adj_indices,\n",
        "            values=reconstructed_values,\n",
        "            dense_shape=adj.shape\n",
        "        )\n",
        "        return reconstructed_adj\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, adj = inputs\n",
        "        z = self.encoder(x, adj)\n",
        "        reconstructed_adj = self.decoder(z, adj.indices)\n",
        "        return reconstructed_adj\n"
      ],
      "metadata": {
        "id": "o3dOND2bXDk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruction_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Loss function between A (original values) and A_hat (predicted values\n",
        "    from the model).\n",
        "    \"\"\"\n",
        "    A = y_true.values\n",
        "    A_reconstructed = y_pred.values\n",
        "\n",
        "    #Limit all values between 0 and 1 in case some of them are too small\n",
        "    A_reconstructed = tf.clip_by_value(A_reconstructed, 1e-6, 1 - 1e-6)  #Avoid log(0)\n",
        "\n",
        "    #Convert A to A_reconstructed format (32 bit)\n",
        "    A = tf.cast(A, dtype=A_reconstructed.dtype)\n",
        "\n",
        "    #Mean squared error loss function\n",
        "    mse_loss = tf.reduce_mean(tf.square(A - A_reconstructed))\n",
        "\n",
        "    return mse_loss"
      ],
      "metadata": {
        "id": "IobdM7pjXKgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model parameter\n",
        "hidden_dim = 64 #capture high information\n",
        "latent_dim = 3 #force clusters formation\n",
        "\n",
        "#Initialize the model\n",
        "gae = GraphAutoencoder(hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
        "\n",
        "#Set optimizer to the initial value of the learning rate\n",
        "init_learning_rate = 0.01\n",
        "optimizer = tf.keras.optimizers.Adam(init_learning_rate)\n",
        "\n",
        "#Set hyperparameters\n",
        "lr_decay_factor = 0.5\n",
        "lr_patience = 5\n",
        "min_lr = 1e-5\n",
        "#set initial best_loss to infinite so first loss will be less\n",
        "best_loss = float(\"inf\")\n",
        "no_improvement_count = 0\n",
        "min_delta = 1e-3\n",
        "\n",
        "\n",
        "#Training loop\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        #Pass data (features) to the model\n",
        "        reconstructed_adj = gae([features, adj_with_self_loops])\n",
        "        negative_values = tf.math.less(reconstructed_adj.values, 0)\n",
        "\n",
        "        #Count how many values are less than zero\n",
        "        count_negative = tf.reduce_sum(tf.cast(negative_values, tf.int32))\n",
        "        print(f\"Number of values less than zero: {count_negative.numpy()}\")\n",
        "\n",
        "        #Compute the loss\n",
        "        loss = reconstruction_loss(adj_with_self_loops, reconstructed_adj)\n",
        "\n",
        "    #Apply gradients\n",
        "    weights_before = [tf.identity(w) for w in gae.trainable_variables]\n",
        "    gradients = tape.gradient(loss, gae.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, gae.trainable_variables))\n",
        "    weights_after = gae.trainable_variables\n",
        "\n",
        "    #Show weights difference after each epoch\n",
        "    for i, (w_before, w_after) in enumerate(zip(weights_before, weights_after)):\n",
        "        print(f\"Layer {i}: Weights difference = {tf.reduce_sum(tf.abs(w_after - w_before)).numpy():.6f}\")\n",
        "\n",
        "    #Update learning rate after 5 epochs of non improvment in loss\n",
        "    if best_loss - loss > min_delta:\n",
        "        best_loss = loss\n",
        "        no_improvement_count = 0  #Reset if loss improves\n",
        "    else:\n",
        "        no_improvement_count += 1\n",
        "    #Update optimizer\n",
        "    if no_improvement_count >= lr_patience:\n",
        "        new_lr = max(optimizer.learning_rate.numpy() * lr_decay_factor, min_lr)\n",
        "        optimizer.learning_rate.assign(new_lr)\n",
        "        print(f\"Learning rate reduced to {new_lr:.6f}\")\n",
        "        #Reset counting\n",
        "        no_improvement_count = 0\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.numpy():.6f}, LR: {optimizer.learning_rate.numpy():.6f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4FTAHF9XSVE",
        "outputId": "86076754-d59e-4ef1-a22a-c01d196c4c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 3.127844\n",
            "Layer 1: Differenza nei pesi = 0.525357\n",
            "Layer 2: Differenza nei pesi = 18.365776\n",
            "Layer 3: Differenza nei pesi = 0.085465\n",
            "Layer 4: Differenza nei pesi = 0.910976\n",
            "Layer 5: Differenza nei pesi = 0.001736\n",
            "Epoch 1/20, Loss: 0.002336, LR: 0.010000\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 2.046196\n",
            "Layer 1: Differenza nei pesi = 0.322843\n",
            "Layer 2: Differenza nei pesi = 12.756344\n",
            "Layer 3: Differenza nei pesi = 0.057811\n",
            "Layer 4: Differenza nei pesi = 0.631131\n",
            "Layer 5: Differenza nei pesi = 0.001172\n",
            "Epoch 2/20, Loss: 0.000425, LR: 0.010000\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 1.602645\n",
            "Layer 1: Differenza nei pesi = 0.250523\n",
            "Layer 2: Differenza nei pesi = 10.180656\n",
            "Layer 3: Differenza nei pesi = 0.044903\n",
            "Layer 4: Differenza nei pesi = 0.492020\n",
            "Layer 5: Differenza nei pesi = 0.000905\n",
            "Epoch 3/20, Loss: 0.000313, LR: 0.010000\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 1.314042\n",
            "Layer 1: Differenza nei pesi = 0.207825\n",
            "Layer 2: Differenza nei pesi = 8.529778\n",
            "Layer 3: Differenza nei pesi = 0.036956\n",
            "Layer 4: Differenza nei pesi = 0.408360\n",
            "Layer 5: Differenza nei pesi = 0.000742\n",
            "Epoch 4/20, Loss: 0.000296, LR: 0.010000\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 1.116577\n",
            "Layer 1: Differenza nei pesi = 0.179206\n",
            "Layer 2: Differenza nei pesi = 7.407573\n",
            "Layer 3: Differenza nei pesi = 0.031455\n",
            "Layer 4: Differenza nei pesi = 0.348505\n",
            "Layer 5: Differenza nei pesi = 0.000630\n",
            "Epoch 5/20, Loss: 0.000289, LR: 0.010000\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 0.971088\n",
            "Layer 1: Differenza nei pesi = 0.157462\n",
            "Layer 2: Differenza nei pesi = 6.550392\n",
            "Layer 3: Differenza nei pesi = 0.027341\n",
            "Layer 4: Differenza nei pesi = 0.306508\n",
            "Layer 5: Differenza nei pesi = 0.000546\n",
            "Epoch 6/20, Loss: 0.000283, LR: 0.010000\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 0.858320\n",
            "Layer 1: Differenza nei pesi = 0.139935\n",
            "Layer 2: Differenza nei pesi = 5.842870\n",
            "Layer 3: Differenza nei pesi = 0.024110\n",
            "Layer 4: Differenza nei pesi = 0.273040\n",
            "Layer 5: Differenza nei pesi = 0.000479\n",
            "Learning rate ridotto a 0.005000\n",
            "Epoch 7/20, Loss: 0.000278, LR: 0.005000\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 0.383739\n",
            "Layer 1: Differenza nei pesi = 0.062655\n",
            "Layer 2: Differenza nei pesi = 2.628156\n",
            "Layer 3: Differenza nei pesi = 0.010742\n",
            "Layer 4: Differenza nei pesi = 0.122951\n",
            "Layer 5: Differenza nei pesi = 0.000213\n",
            "Epoch 8/20, Loss: 0.000273, LR: 0.005000\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 0.345483\n",
            "Layer 1: Differenza nei pesi = 0.056865\n",
            "Layer 2: Differenza nei pesi = 2.383489\n",
            "Layer 3: Differenza nei pesi = 0.009647\n",
            "Layer 4: Differenza nei pesi = 0.111650\n",
            "Layer 5: Differenza nei pesi = 0.000190\n",
            "Epoch 9/20, Loss: 0.000270, LR: 0.005000\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 0.313374\n",
            "Layer 1: Differenza nei pesi = 0.052123\n",
            "Layer 2: Differenza nei pesi = 2.179141\n",
            "Layer 3: Differenza nei pesi = 0.008719\n",
            "Layer 4: Differenza nei pesi = 0.102113\n",
            "Layer 5: Differenza nei pesi = 0.000171\n",
            "Epoch 10/20, Loss: 0.000268, LR: 0.005000\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 0.285901\n",
            "Layer 1: Differenza nei pesi = 0.048030\n",
            "Layer 2: Differenza nei pesi = 2.003214\n",
            "Layer 3: Differenza nei pesi = 0.007920\n",
            "Layer 4: Differenza nei pesi = 0.093960\n",
            "Layer 5: Differenza nei pesi = 0.000155\n",
            "Epoch 11/20, Loss: 0.000266, LR: 0.005000\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 0.261842\n",
            "Layer 1: Differenza nei pesi = 0.044764\n",
            "Layer 2: Differenza nei pesi = 1.847651\n",
            "Layer 3: Differenza nei pesi = 0.007225\n",
            "Layer 4: Differenza nei pesi = 0.086901\n",
            "Layer 5: Differenza nei pesi = 0.000140\n",
            "Learning rate ridotto a 0.002500\n",
            "Epoch 12/20, Loss: 0.000264, LR: 0.002500\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 0.120158\n",
            "Layer 1: Differenza nei pesi = 0.020906\n",
            "Layer 2: Differenza nei pesi = 0.853771\n",
            "Layer 3: Differenza nei pesi = 0.003329\n",
            "Layer 4: Differenza nei pesi = 0.040356\n",
            "Layer 5: Differenza nei pesi = 0.000064\n",
            "Epoch 13/20, Loss: 0.000262, LR: 0.002500\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 0.110740\n",
            "Layer 1: Differenza nei pesi = 0.019604\n",
            "Layer 2: Differenza nei pesi = 0.791966\n",
            "Layer 3: Differenza nei pesi = 0.003093\n",
            "Layer 4: Differenza nei pesi = 0.037618\n",
            "Layer 5: Differenza nei pesi = 0.000058\n",
            "Epoch 14/20, Loss: 0.000261, LR: 0.002500\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 0.102444\n",
            "Layer 1: Differenza nei pesi = 0.018441\n",
            "Layer 2: Differenza nei pesi = 0.737015\n",
            "Layer 3: Differenza nei pesi = 0.002888\n",
            "Layer 4: Differenza nei pesi = 0.035179\n",
            "Layer 5: Differenza nei pesi = 0.000053\n",
            "Epoch 15/20, Loss: 0.000260, LR: 0.002500\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 0.095317\n",
            "Layer 1: Differenza nei pesi = 0.017404\n",
            "Layer 2: Differenza nei pesi = 0.687914\n",
            "Layer 3: Differenza nei pesi = 0.002707\n",
            "Layer 4: Differenza nei pesi = 0.032993\n",
            "Layer 5: Differenza nei pesi = 0.000049\n",
            "Epoch 16/20, Loss: 0.000259, LR: 0.002500\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 0.089169\n",
            "Layer 1: Differenza nei pesi = 0.016481\n",
            "Layer 2: Differenza nei pesi = 0.643765\n",
            "Layer 3: Differenza nei pesi = 0.002545\n",
            "Layer 4: Differenza nei pesi = 0.031039\n",
            "Layer 5: Differenza nei pesi = 0.000045\n",
            "Learning rate ridotto a 0.001250\n",
            "Epoch 17/20, Loss: 0.000258, LR: 0.001250\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 0.041832\n",
            "Layer 1: Differenza nei pesi = 0.007841\n",
            "Layer 2: Differenza nei pesi = 0.302414\n",
            "Layer 3: Differenza nei pesi = 0.001201\n",
            "Layer 4: Differenza nei pesi = 0.014638\n",
            "Layer 5: Differenza nei pesi = 0.000021\n",
            "Epoch 18/20, Loss: 0.000258, LR: 0.001250\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 0.039476\n",
            "Layer 1: Differenza nei pesi = 0.007531\n",
            "Layer 2: Differenza nei pesi = 0.285580\n",
            "Layer 3: Differenza nei pesi = 0.001136\n",
            "Layer 4: Differenza nei pesi = 0.013858\n",
            "Layer 5: Differenza nei pesi = 0.000019\n",
            "Epoch 19/20, Loss: 0.000257, LR: 0.001250\n",
            "\n",
            "Numero di valori minori di zero: 0\n",
            "Layer 0: Differenza nei pesi = 0.037433\n",
            "Layer 1: Differenza nei pesi = 0.007258\n",
            "Layer 2: Differenza nei pesi = 0.270908\n",
            "Layer 3: Differenza nei pesi = 0.001079\n",
            "Layer 4: Differenza nei pesi = 0.013159\n",
            "Layer 5: Differenza nei pesi = 0.000018\n",
            "Epoch 20/20, Loss: 0.000257, LR: 0.001250\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Show latent embedding layer z (features tensor after the model was applied)\n",
        "z = gae.encoder(features, adj_with_self_loops)\n",
        "z_numpy = z.numpy()\n",
        "print(\"Shape di z_numpy (NumPy):\", z_numpy.shape)\n",
        "print(z_numpy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPV_8XH6INua",
        "outputId": "95a1ccb2-15c1-4a3d-875e-b6c89cc77c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape di z_numpy (NumPy): (159805, 3)\n",
            "[[ 0.5199357  -0.39485395  0.7574675 ]\n",
            " [ 0.51171243 -0.29608056  0.80652744]\n",
            " [ 0.51994675 -0.39086345  0.7595269 ]\n",
            " ...\n",
            " [ 0.31650653 -0.65099126  0.6899521 ]\n",
            " [ 0.36073747 -0.7535651   0.5495528 ]\n",
            " [ 0.3076424  -0.63321763  0.7102052 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Keep correspondence between z_numpy and initial features (in rad and dec).\n",
        "#Create z matrix with additional features for every object (object ra and dec)\n",
        "ra_dec_array = np.array([filtered_table['RIGHT_ASCENSION'],\n",
        "                         filtered_table['DECLINATION']]).T\n",
        "z_numpy_with_ra_dec = np.concatenate([z_numpy, ra_dec_array], axis=1)\n",
        "print(z_numpy_with_ra_dec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb2WJALYKCPw",
        "outputId": "3751923d-bb60-4e34-e164-b41e51518c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0.5199357   -0.39485395   0.7574675  148.6701       1.5350571 ]\n",
            " [  0.51171243  -0.29608056   0.80652744 148.67267      1.5331802 ]\n",
            " [  0.51994675  -0.39086345   0.7595269  148.67853      1.5378342 ]\n",
            " ...\n",
            " [  0.31650653  -0.65099126   0.6899521  148.76233      2.1816025 ]\n",
            " [  0.36073747  -0.7535651    0.5495528  148.74994      2.1999893 ]\n",
            " [  0.3076424   -0.63321763   0.7102052  148.70917      2.2895203 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#K-means algorithm on the embedding features, after the model was applied\n",
        "\n",
        "range_k = range(5, 30)  #try with different k\n",
        "inertias = []\n",
        "\n",
        "for i in range_k:\n",
        "    kmeans = KMeans(init = \"k-means++\", n_clusters = i, n_init = 12)\n",
        "    kmeans.fit(z_numpy)\n",
        "    inertias.append(kmeans.inertia_)"
      ],
      "metadata": {
        "id": "3Vh0m8bOMqVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find elbow point\n",
        "knee_locator = KneeLocator(range_k, inertias, curve=\"convex\", direction=\"decreasing\")\n",
        "print(\"Best number of clusters:\", knee_locator.knee)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L34ufxOaNNSl",
        "outputId": "88bbe3d0-e427-4b8d-8861-b690c576cf74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best number of clusters: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=knee_locator.knee, n_init=12)\n",
        "kmeans.fit(z_numpy)\n",
        "\n",
        "#Show results\n",
        "centri_clusters = kmeans.cluster_centers_\n",
        "\n",
        "print(\"Clusters centers:\")\n",
        "print(centri_clusters)\n",
        "\n",
        "cluster_labels = kmeans.labels_\n",
        "distances = kmeans.transform(z_numpy)\n",
        "\n",
        "#Count elements for each cluster\n",
        "n_elementi_per_cluster = np.bincount(cluster_labels)\n",
        "\n",
        "print(\"Number of elements for every cluster:\")\n",
        "for cluster, count in enumerate(n_elementi_per_cluster):\n",
        "    print(f\"Cluster {cluster}: {count} elements\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKuczkiQUc6_",
        "outputId": "984114d4-50b9-49fa-ddf9-8d2e97043aa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centri dei cluster trovati:\n",
            "[[ 0.3312029  -0.4951792   0.79972935]\n",
            " [ 0.23669782 -0.8699901   0.4220965 ]\n",
            " [ 0.5032504  -0.539619    0.669855  ]\n",
            " [ 0.47849643 -0.36936164  0.7926298 ]\n",
            " [ 0.19185047 -0.77162033  0.59920776]\n",
            " [ 0.36788705 -0.22134659  0.8986001 ]\n",
            " [ 0.17551951 -0.59700364  0.7776899 ]\n",
            " [ 0.43374655 -0.82213485  0.35596022]\n",
            " [ 0.30173084 -0.92494345  0.20843914]\n",
            " [ 0.23098357 -0.35827377  0.8994949 ]\n",
            " [ 0.46903893 -0.70299745  0.5264753 ]\n",
            " [ 0.3463828  -0.6467362   0.67504513]]\n",
            "Numero di elementi per cluster:\n",
            "Cluster 0: 16049 elementi\n",
            "Cluster 1: 11513 elementi\n",
            "Cluster 2: 15207 elementi\n",
            "Cluster 3: 13885 elementi\n",
            "Cluster 4: 11122 elementi\n",
            "Cluster 5: 13168 elementi\n",
            "Cluster 6: 11702 elementi\n",
            "Cluster 7: 12232 elementi\n",
            "Cluster 8: 11061 elementi\n",
            "Cluster 9: 11679 elementi\n",
            "Cluster 10: 17231 elementi\n",
            "Cluster 11: 14956 elementi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Apply random reduction of the elements of every cluster using the median\n",
        "absolute deviation to reduce the influence of outliers and standard deviations\n",
        "afterwards.\n",
        "\"\"\"\n",
        "\n",
        "#Create a list with only three features and another adding ra and dec, but\n",
        "#keeping correspondence in index\n",
        "filtered_clusters = []\n",
        "filtered_clusters_with_ra_dec = []\n",
        "\n",
        "for cluster in np.unique(cluster_labels):\n",
        "    cluster_indices = np.where(cluster_labels == cluster)[0]\n",
        "    cluster_distances = distances[cluster_indices, cluster]\n",
        "    distances_median = np.median(cluster_distances)\n",
        "\n",
        "    #Apply MAD - Median Absolute Deviation\n",
        "    mad = np.median(np.abs(cluster_distances - distances_median))\n",
        "    cluster_threshold_upper_mad = distances_median + mad\n",
        "    cluster_threshold_lower_mad = distances_median - mad\n",
        "\n",
        "    #Determine initial inliers using MAD\n",
        "    cluster_indices_inliers = np.where(\n",
        "        (cluster_distances <= cluster_threshold_upper_mad)\n",
        "        & (cluster_distances >= cluster_threshold_lower_mad))[0]\n",
        "\n",
        "    #Determine initial outliers using MAD\n",
        "    cluster_indices_outliers = np.where(\n",
        "        (cluster_distances > cluster_threshold_upper_mad) |\n",
        "        (cluster_distances < cluster_threshold_lower_mad))[0]\n",
        "\n",
        "    #Keep deleting outliers from every cluster until they are less than 10\n",
        "    while len(cluster_indices_outliers) > 10:\n",
        "        cluster_distances_new = distances[cluster_indices_inliers, cluster]\n",
        "        distances_mean = np.mean(cluster_distances_new)\n",
        "        #Use standard deviation from now on\n",
        "        std_dev = np.std(cluster_distances_new)\n",
        "        cluster_threshold_upper_std = distances_mean + 2*std_dev\n",
        "        cluster_threshold_lower_std = distances_mean - 2*std_dev\n",
        "\n",
        "        cluster_indices_inliers = np.where(\n",
        "            (cluster_distances_new <= cluster_threshold_upper_std)\n",
        "            & (cluster_distances_new >= cluster_threshold_lower_std))[0]\n",
        "\n",
        "        cluster_indices_outliers = np.where(\n",
        "            (cluster_distances_new > cluster_threshold_upper_std)\n",
        "            | (cluster_distances_new < cluster_threshold_lower_std))[0]\n",
        "\n",
        "    filtered_clusters.append(z_numpy[cluster_indices_inliers])\n",
        "    filtered_clusters_with_ra_dec.append(z_numpy_with_ra_dec[cluster_indices_inliers])\n",
        "\n",
        "filtered_clusters = np.vstack(filtered_clusters)\n",
        "filtered_clusters_with_ra_dec = np.vstack(filtered_clusters_with_ra_dec)\n"
      ],
      "metadata": {
        "id": "uZyyr51Wz0b0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#K-means with filtered_clusters\n",
        "\n",
        "range_k = range(5, 30)\n",
        "inertias = []\n",
        "\n",
        "for i in range_k:\n",
        "    kmeans = KMeans(init = \"k-means++\", n_clusters = i, n_init = 12)\n",
        "    kmeans.fit(filtered_clusters)\n",
        "    inertias.append(kmeans.inertia_)"
      ],
      "metadata": {
        "id": "M0JYcp4ZIG7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find elbow point\n",
        "knee_locator = KneeLocator(range_k, inertias, curve=\"convex\", direction=\"decreasing\")\n",
        "print(\"Best number of clusters:\", knee_locator.knee)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhWTyQrSITPR",
        "outputId": "00e55448-fab8-4d4e-d7a8-88f5e91475ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best number of clusters: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=knee_locator.knee, n_init=12)\n",
        "kmeans.fit(filtered_clusters)\n",
        "\n",
        "#Show results\n",
        "centri_clusters_post = kmeans.cluster_centers_\n",
        "\n",
        "print(\"Cluster centers:\")\n",
        "print(centri_clusters)\n",
        "\n",
        "cluster_labels_post = kmeans.labels_\n",
        "\n",
        "#Count number of elements for each cluster\n",
        "n_elementi_per_cluster = np.bincount(cluster_labels_post)\n",
        "\n",
        "print(\"Number of elements in every cluster:\")\n",
        "for cluster, count in enumerate(n_elementi_per_cluster):\n",
        "    print(f\"Cluster {cluster}: {count} elements\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUuPouNgIbxM",
        "outputId": "684f0dd2-4104-458d-a4ab-38878994bdc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centri dei cluster trovati:\n",
            "[[ 0.3312029  -0.4951792   0.79972935]\n",
            " [ 0.23669782 -0.8699901   0.4220965 ]\n",
            " [ 0.5032504  -0.539619    0.669855  ]\n",
            " [ 0.47849643 -0.36936164  0.7926298 ]\n",
            " [ 0.19185047 -0.77162033  0.59920776]\n",
            " [ 0.36788705 -0.22134659  0.8986001 ]\n",
            " [ 0.17551951 -0.59700364  0.7776899 ]\n",
            " [ 0.43374655 -0.82213485  0.35596022]\n",
            " [ 0.30173084 -0.92494345  0.20843914]\n",
            " [ 0.23098357 -0.35827377  0.8994949 ]\n",
            " [ 0.46903893 -0.70299745  0.5264753 ]\n",
            " [ 0.3463828  -0.6467362   0.67504513]]\n",
            "Numero di elementi per cluster:\n",
            "Cluster 0: 920 elementi\n",
            "Cluster 1: 527 elementi\n",
            "Cluster 2: 837 elementi\n",
            "Cluster 3: 440 elementi\n",
            "Cluster 4: 677 elementi\n",
            "Cluster 5: 753 elementi\n",
            "Cluster 6: 444 elementi\n",
            "Cluster 7: 665 elementi\n",
            "Cluster 8: 657 elementi\n",
            "Cluster 9: 480 elementi\n",
            "Cluster 10: 429 elementi\n",
            "Cluster 11: 632 elementi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Silhouette Score before and after filtering\n",
        "silhouette_avg = silhouette_score(z_numpy, cluster_labels)\n",
        "\n",
        "print(f\"Mean Silhouette Score: {silhouette_avg}\")\n",
        "\n",
        "\n",
        "silhouette_avg_post = silhouette_score(filtered_clusters, cluster_labels_post)\n",
        "\n",
        "print(f\"Mean Silhouette Score after filtering: {silhouette_avg_post}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek9wnt3TmmPC",
        "outputId": "80834830-532f-4365-8ed2-77dffd22f00b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score medio: 0.3427370488643646\n",
            "Silhouette Score medio dopo filtraggio: 0.3772273063659668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calinski Harabasz Score before and after flitering\n",
        "ch_score = calinski_harabasz_score(z_numpy, cluster_labels)\n",
        "print(f\"Calinski-Harabasz Score: {ch_score}\")\n",
        "\n",
        "ch_score_post = calinski_harabasz_score(filtered_clusters, cluster_labels_post)\n",
        "print(f\"Calinski-Harabasz Score after filtering: {ch_score_post}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0lrOzzKszIY",
        "outputId": "70cfddf7-dec4-4a0f-b6a4-b4c582226720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calinski-Harabasz Score: 174857.97040454394\n",
            "Calinski-Harabasz Score: 8519.099876431039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_centers_and_radia = []\n",
        "\n",
        "#Find RA and DEC of every cluster center\n",
        "for cluster_label in np.unique(cluster_labels_post):\n",
        "    #Get data for the current cluster\n",
        "    cluster_data = filtered_clusters_with_ra_dec[cluster_labels_post == cluster_label]\n",
        "    ra_dec_data = cluster_data[:, -2:]  #Pick only last two columns (Ra and Dec)\n",
        "\n",
        "    #Find cluster center as (ra,dec)\n",
        "    center = np.mean(ra_dec_data, axis=0)\n",
        "\n",
        "    #Compute max and mean radius for every cluster\n",
        "    distances = np.sqrt(np.sum((ra_dec_data - center) ** 2, axis=1))\n",
        "    radius_max = np.max(distances)\n",
        "    radius_mean = np.mean(distances)\n",
        "\n",
        "    #List with centers and radia\n",
        "    cluster_centers_and_radia.append((center, radius_mean, radius_max))\n",
        "\n",
        "    print(f\"Cluster number:, {cluster_label:.5f}, center: [{center[0]:.5f},{center[1]:.5f}]\")\n",
        "    print(f\"maximum radius: {radius_max:.5f}, mean radius: {radius_mean:.5f}.\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deKhvmgchSu3",
        "outputId": "dd91682f-98c9-40af-cead-85287d76af9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster number:, 0, center: [148.2943      1.7421131]\n",
            "maximum radius: 0.7027941942214966, mean radius: 0.27212727069854736.\n",
            "\n",
            "Cluster number:, 1, center: [148.21521     2.0762205]\n",
            "maximum radius: 0.5808811187744141, mean radius: 0.19195765256881714.\n",
            "\n",
            "Cluster number:, 2, center: [148.60046     1.6382128]\n",
            "maximum radius: 0.3103255033493042, mean radius: 0.12304067611694336.\n",
            "\n",
            "Cluster number:, 3, center: [148.23235    1.867824]\n",
            "maximum radius: 0.6622401475906372, mean radius: 0.2915003001689911.\n",
            "\n",
            "Cluster number:, 4, center: [148.3513     1.723611]\n",
            "maximum radius: 0.692415714263916, mean radius: 0.2910735607147217.\n",
            "\n",
            "Cluster number:, 5, center: [148.62563     1.7211549]\n",
            "maximum radius: 0.29718953371047974, mean radius: 0.15579475462436676.\n",
            "\n",
            "Cluster number:, 6, center: [148.26538    2.141495]\n",
            "maximum radius: 0.4321249723434448, mean radius: 0.18252351880073547.\n",
            "\n",
            "Cluster number:, 7, center: [148.55695     1.9382267]\n",
            "maximum radius: 0.4998573064804077, mean radius: 0.16647346317768097.\n",
            "\n",
            "Cluster number:, 8, center: [148.53433     1.6848291]\n",
            "maximum radius: 0.4878444969654083, mean radius: 0.20371322333812714.\n",
            "\n",
            "Cluster number:, 9, center: [148.31464     1.8653436]\n",
            "maximum radius: 0.6181745529174805, mean radius: 0.2698749005794525.\n",
            "\n",
            "Cluster number:, 10, center: [148.15324     2.1415954]\n",
            "maximum radius: 0.44505611062049866, mean radius: 0.17323437333106995.\n",
            "\n",
            "Cluster number:, 11, center: [148.39345     2.0881155]\n",
            "maximum radius: 0.4560524821281433, mean radius: 0.22231698036193848.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cluster_centers_and_radia)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVLy4oPem10N",
        "outputId": "2f1a52a2-19e5-43b1-ea13-df4fd694fb45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(array([148.2943   ,   1.7421131], dtype=float32), 0.27212727, 0.7027942), (array([148.21521  ,   2.0762205], dtype=float32), 0.19195765, 0.5808811), (array([148.60046  ,   1.6382128], dtype=float32), 0.123040676, 0.3103255), (array([148.23235 ,   1.867824], dtype=float32), 0.2915003, 0.66224015), (array([148.3513  ,   1.723611], dtype=float32), 0.29107356, 0.6924157), (array([148.62563  ,   1.7211549], dtype=float32), 0.15579475, 0.29718953), (array([148.26538 ,   2.141495], dtype=float32), 0.18252352, 0.43212497), (array([148.55695  ,   1.9382267], dtype=float32), 0.16647346, 0.4998573), (array([148.53433  ,   1.6848291], dtype=float32), 0.20371322, 0.4878445), (array([148.31464  ,   1.8653436], dtype=float32), 0.2698749, 0.61817455), (array([148.15324  ,   2.1415954], dtype=float32), 0.17323437, 0.4450561), (array([148.39345  ,   2.0881155], dtype=float32), 0.22231698, 0.45605248)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path1 = '/content/drive/My Drive/galaxy_clusters.FS2.1_halos_with_true_richness_30deg2_ngal10.txt'"
      ],
      "metadata": {
        "id": "2w7uYoawJIZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(file_path1, sep='\\s+')\n",
        "df.columns = df.columns.str.strip()\n",
        "radia_z_data_true = df[[ 'rs_halo', 'rvir_halo', 'true_redshift_gal']].values\n",
        "ra_dec_data_true = df[['ra_gal', 'dec_gal']].values\n",
        "\n",
        "#Print some useful information\n",
        "print(\"Column names after stripping:\", df.columns.tolist())\n",
        "print(\"Shape of ra_dec_data:\", ra_dec_data_true.shape)\n",
        "print(\"Minimum of ra:\", ra_dec_data_true[:,0].min())\n",
        "print(\"Maximum of ra:\", ra_dec_data_true[:,0].max())\n",
        "print(\"Minimum of dec:\", ra_dec_data_true[:,1].min())\n",
        "print(\"Maximum of dec:\", ra_dec_data_true[:,1].max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgNnD8ciJ1LI",
        "outputId": "0fa2ace3-1e86-48be-8492-f51df31ede24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names after stripping: ['halo_id', 'galaxy_id', 'kind', 'lm_halo', 'n_sats_halo', 'rs_halo', 'rvir_halo', 'ra_gal', 'dec_gal', 'true_redshift_gal', 'observed_redshift_gal', 'euclid_vis', 'euclid_nisp_y', 'euclid_nisp_j', 'euclid_nisp_h', 'lsst_g', 'lsst_i', 'lsst_r', 'lsst_y', 'lsst_z', 'mw_extinction', 'richness_mag24', 'richness_true_dm1.5', 'richness_true_dm2.0']\n",
            "Shape of ra_dec_data: (15766, 2)\n",
            "Minimum of ra: 146.00024\n",
            "Maximum of ra: 151.49976\n",
            "Minimum of dec: 1.0031204\n",
            "Maximum of dec: 6.499687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find matching clusters (centers)\n",
        "matching_centers = []\n",
        "matching_radia = []\n",
        "matched_centers = []\n",
        "matched_centers_radia_z = []\n",
        "\n",
        "#Create a structured array with fixed tipes\n",
        "dtype = [('centers', float, 2), ('radia_mean', float), ('radia_max', float)]\n",
        "cluster_centers_and_radia = np.array(cluster_centers_and_radia, dtype = dtype)\n",
        "\n",
        "#Define constants\n",
        "c = 299792\n",
        "H0 = 70\n",
        "\n",
        "for element in cluster_centers_and_radia:\n",
        "    #Trova se il centro è presente nei dati, restituisce un array booleano con\n",
        "    #valori True o False se la coppia di ra e dec corrisponde al centro\n",
        "    #element[0] = centri trovati da me, element[1] = raggi media miei\n",
        "    #element[2] = raggi massimi miei\n",
        "    matches = np.isclose(ra_dec_data_true, element['centers'], atol=0.01).all(axis=1)\n",
        "    #If there is correspondence\n",
        "    if matches.any():\n",
        "        matching_centers.append(element['centers'])\n",
        "        matching_radia.append((element['radia_mean'], element['radia_max']))\n",
        "        matched_centers.append(ra_dec_data_true[matches])\n",
        "        matched_centers_radia_z.append(radia_z_data_true[matches])\n",
        "\n",
        "#Show matching centers\n",
        "if matching_centers:\n",
        "    print(\"Centers that correspond to actual centers:\\n\")\n",
        "    for center, radia, true_centers, radia_and_z in zip(matching_centers,\n",
        "                                        matching_radia,matched_centers,\n",
        "                                        matched_centers_radia_z):\n",
        "        print(f\"Center [{center[0]:.4f},{center[1]:.4f}] with mean radius: {radia[0]:.4f} e maximum: {radia[1]:.4f}, correspond to:\")\n",
        "        for row1, row2 in zip(true_centers, radia_and_z):\n",
        "            distance = cosmo.comoving_distance(row2[2]).value*1000 #in kpac\n",
        "            theta_rs_deg = np.degrees(row2[0] / distance)  #Raggio angolare in gradi\n",
        "            theta_rvir_deg = np.degrees(row2[1]/distance)  #Raggio viriale in gradi\n",
        "            print(f\"[{row1[0]:.4f},{row1[1]:.4f}]\")\n",
        "            print(f\"with scale radius {theta_rs_deg:.4f} degrees and virial radius {theta_rvir_deg:.4f} degrees.\")\n",
        "        print(\"\\n\\n\")\n",
        "    print(f\"{len(matching_centers)} correspondig centers found out of {knee_locator.knee}\")\n",
        "else:\n",
        "    print(\"No center correspond to the your found center.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1TgaTvTzOVl",
        "outputId": "51920842-a6a5-4693-bd22-32dfae1c08a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centri che coincidono con i dati veri:\n",
            "\n",
            "Centro [148.2943,1.7421] con raggio medio: 0.2721 e massimo: 0.7028, corrisponde a:\n",
            "[148.2978,1.7388]\n",
            "con raggio di scala 0.0031 gradi e raggio viriale 0.0092 gradi.\n",
            "\n",
            "\n",
            "\n",
            "Centro [148.2323,1.8678] con raggio medio: 0.2915 e massimo: 0.6622, corrisponde a:\n",
            "[148.2249,1.8756]\n",
            "con raggio di scala 0.0025 gradi e raggio viriale 0.0201 gradi.\n",
            "\n",
            "\n",
            "\n",
            "Centro [148.2654,2.1415] con raggio medio: 0.1825 e massimo: 0.4321, corrisponde a:\n",
            "[148.2754,2.1398]\n",
            "con raggio di scala 0.0028 gradi e raggio viriale 0.0161 gradi.\n",
            "\n",
            "\n",
            "\n",
            "Centro [148.5569,1.9382] con raggio medio: 0.1665 e massimo: 0.4999, corrisponde a:\n",
            "[148.5660,1.9482]\n",
            "con raggio di scala 0.0026 gradi e raggio viriale 0.0158 gradi.\n",
            "[148.5532,1.9397]\n",
            "con raggio di scala 0.0027 gradi e raggio viriale 0.0086 gradi.\n",
            "\n",
            "\n",
            "\n",
            "Centro [148.5343,1.6848] con raggio medio: 0.2037 e massimo: 0.4878, corrisponde a:\n",
            "[148.5292,1.6831]\n",
            "con raggio di scala 0.0044 gradi e raggio viriale 0.0143 gradi.\n",
            "\n",
            "\n",
            "\n",
            "Centro [148.3146,1.8653] con raggio medio: 0.2699 e massimo: 0.6182, corrisponde a:\n",
            "[148.3068,1.8596]\n",
            "con raggio di scala 0.0032 gradi e raggio viriale 0.0150 gradi.\n",
            "\n",
            "\n",
            "\n",
            "6 centri corrispondenti trovati su 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dBwKdBfCyVm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puoi provare a normalizzare z_numpy tra 0 e 1 prima di effettuare clustering, magari i raggi medio e massimo diminuiscono un po'."
      ],
      "metadata": {
        "id": "QvNkoOuI1HKI"
      }
    }
  ]
}